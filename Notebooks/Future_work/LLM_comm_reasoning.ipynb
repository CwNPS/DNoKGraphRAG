{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoning from community summaries\n",
    "_NOTE: Future work_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO for this notebook:\n",
    "- intermediate test case doesnt generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_path = \"../data/exp_outputs/comm_reasoning_output.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hugging Face is a technology company based in New York and Paris that specializes in natural language processing (NLP). They are known for their popular open-source library, Transformers, which provides pre-trained models for various NLP tasks such as text classification, question answering, language translation, and more. They also offer a platform for developers to train, evaluate, and deploy machine learning models.\n",
      "\n",
      "Additionally, Hugging Face provides a model hub where developers can share, discover, and use pre-trained models. They also offer a token-based API for accessing these models, making it easy for developers to integrate NLP functionality into their applications.\n",
      "\n",
      "In summary, Hugging Face is a company that focuses on making NLP more accessible and useful by providing open-source tools, pre-trained models, and a platform for developers to build and deploy NLP applications.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "#Initialize the model endpoint\n",
    "HOST_URL_INF = \":8080\"\n",
    "MAX_NEW_TOKENS = 1200\n",
    "\n",
    "TEMPERATURE = 0.3\n",
    "TIMEOUT = 180\n",
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    endpoint_url=HOST_URL_INF,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=MAX_NEW_TOKENS,\n",
    "    do_sample=True,\n",
    "    temperature = TEMPERATURE,\n",
    "    timeout=TIMEOUT,\n",
    ")\n",
    "print(llm.invoke(\"What is HuggingFace?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test profiles\n",
    "- Generated by GPT4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1 = {\n",
    "    \"test_case\": \"Beginner Test Case->\",\n",
    "    \"name\": \"Priya Gupta\",\n",
    "    \"learning_objectives\": \"\"\"\n",
    "        Understand the fundamentals of linear programming.\n",
    "        Learn how to use Python for optimization problems.\n",
    "        Solve real-world transportation and assignment problems.\n",
    "    \"\"\",\n",
    "    \"profile\": \"\"\"\n",
    "        Background: Recent college graduate with a degree in Business Administration.\n",
    "        Strengths: Strong organizational and project management skills.\n",
    "        Weaknesses: Limited mathematical background; no prior programming experience.\n",
    "        Preferences: Prefers real-world applications, interactive learning, and visualizations.\n",
    "    \"\"\"\n",
    "}\n",
    "student_2 = {\n",
    "    \"test_case\": \"Intermediate Test Case->\",\n",
    "    \"name\": \"David Martinez\",\n",
    "    \"learning_objectives\": \"\"\"\n",
    "        Master integer programming techniques.\n",
    "        Explore stochastic models like Markov chains and inventory models.\n",
    "        Build a simulation model for decision-making using Monte Carlo methods.\n",
    "    \"\"\",\n",
    "    \"profile\": \"\"\"\n",
    "        Background: Graduate student pursuing an Industrial Engineering degree with some exposure to optimization.\n",
    "        Strengths: Comfortable with mathematical modeling and programming in Python.\n",
    "        Weaknesses: Lacks practical experience with stochastic and simulation models.\n",
    "        Preferences: Prefers structured lessons with hands-on coding exercises and case studies.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "student_3 = {\n",
    "    \"test_case\": \"Advanced Test Case->\",\n",
    "    \"name\": \"Emma Lee\",\n",
    "    \"learning_objectives\": \"\"\"\n",
    "        Apply nonlinear programming to optimize complex supply chain models.\n",
    "        Develop advanced algorithms using Python libraries like PuLP and Gurobi.\n",
    "        Implement decision analysis frameworks for high-level operational strategy.\n",
    "    \"\"\",\n",
    "    \"profile\": \"\"\"\n",
    "        Background: Operations Research professional with 5 years of experience working in logistics optimization.\n",
    "        Strengths: Deep understanding of OR concepts and programming expertise.\n",
    "        Weaknesses: Limited familiarity with advanced nonlinear programming and computational tools beyond Excel.\n",
    "        Preferences: Prefers self-paced learning with technical documentation and challenging projects.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "students = [student_1, student_2, student_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Student Profile:\n",
    "- Name: {student_name}\n",
    "- Learning Objectives: {learning_objectives}\n",
    "- Profile Details: {student_profile}\n",
    "\n",
    "Tasks:\n",
    "1. Based on the provided profile and learning objectives, determine the optimal learning path(s) (including order) to achieve all objectives.\n",
    "2. Identify and list specific content aligns with and supports the optimal path(s). Use additional context if provided.\n",
    "3. Suggest alternative or backup content that can replace the primary content identified in case of availability issues or better alignment with the student's preferences.\n",
    "4. Respond to the request with text output.\n",
    "\n",
    "Additional Context:\n",
    "{context}\n",
    "\n",
    "Request: \n",
    "{learning_request}\n",
    "\n",
    "Output:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_2 = \"\"\" \n",
    "Student Profile:\n",
    "- Name: {student_name}\n",
    "- Learning Objectives: {learning_objectives}\n",
    "- Profile Details: {student_profile}\n",
    "\n",
    "Tasks:\n",
    "1. Based on the provided profile and learning objectives, design a comprehensive learning plan organized into **phases** with specific topics and timeframes. Each phase should build on the previous one, ensuring a structured progression.\n",
    "2. Identify and map content to support each phase and objective. Use additional context if provided. Include recommended resources such as textbooks, online courses, software, or tools that align with the objectives.\n",
    "3. Provide practical study strategies tailored to the student's profile, including time allocations, practice methods, and checkpoint assessments to measure progress.\n",
    "4. Suggest alternative or backup content that can replace primary resources in case of availability issues or better alignment with the student's preferences.\n",
    "5. Respond to the request with text output in the example format.\n",
    "\n",
    "Additional Context:\n",
    "{context}\n",
    "\n",
    "Output Format:\n",
    "1. Learning Plan:\n",
    "   - **Phase 1:** [Name] (e.g., Mathematical Foundations) - [Duration]\n",
    "     - [Topics/Objectives and Subtopics]\n",
    "   - **Phase 2:** [Name] (e.g., Core OR Concepts) - [Duration]\n",
    "     - [Topics/Objectives and Subtopics]\n",
    "   - **Phase 3:** [Name] (e.g., Advanced Topics) - [Duration]\n",
    "     - [Topics/Objectives and Subtopics]\n",
    "   - **Phase 4:** [Name] (e.g., Computational Tools) - [Duration]\n",
    "     - [Topics/Objectives and Subtopics]\n",
    "\n",
    "2. Primary Content Mapping:\n",
    "   - Phase 1:\n",
    "     - Subtopic 1: [Resource/Content from NoK]\n",
    "     - Subtopic 2: [Resource/Content from NoK]\n",
    "   - Phase 2:\n",
    "     ...\n",
    "   - Phase 3:\n",
    "     ...\n",
    "   - Phase 4:\n",
    "     ...\n",
    "\n",
    "3. Study Strategies and Tips:\n",
    "   - Weekly schedule template with time allocation for review, practice, problem-solving, and theory.\n",
    "   - Recommended practice methods, such as implementing algorithms, visualization, and community involvement.\n",
    "   - Self-assessment checkpoints.\n",
    "\n",
    "4. Backup Content Suggestions:\n",
    "   - Phase 1:\n",
    "     - Subtopic 1: [Backup Resource]\n",
    "     - Subtopic 2: [Backup Resource]\n",
    "   - Phase 2:\n",
    "     ...\n",
    "   - Phase 3:\n",
    "     ...\n",
    "   - Phase 4:\n",
    "     ...\n",
    "\n",
    "Request: \n",
    "{learning_request}\n",
    "\n",
    "Output:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Student Profile:\n",
      "- Name: Priya Gupta\n",
      "- Learning Objectives: \n",
      "        Understand the fundamentals of linear programming.\n",
      "        Learn how to use Python for optimization problems.\n",
      "        Solve real-world transportation and assignment problems.\n",
      "    \n",
      "- Profile Details: \n",
      "        Background: Recent college graduate with a degree in Business Administration.\n",
      "        Strengths: Strong organizational and project management skills.\n",
      "        Weaknesses: Limited mathematical background; no prior programming experience.\n",
      "        Preferences: Prefers real-world applications, interactive learning, and visualizations.\n",
      "    \n",
      "\n",
      "Tasks:\n",
      "1. Based on the provided profile and learning objectives, determine the optimal learning path(s) (including order) to achieve all objectives.\n",
      "2. Identify and list specific content aligns with and supports the optimal path(s). Use additional context if provided.\n",
      "3. Suggest alternative or backup content that can replace the primary content identified in case of availability issues or better alignment with the student's preferences.\n",
      "4. Respond to the request with text output.\n",
      "\n",
      "Additional Context:\n",
      "\n",
      "\n",
      "Request: \n",
      "Generate an individualized learning plan tailored to the student's needs.\n",
      "\n",
      "Output:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test prompt format\n",
    "prompt = prompt_template.format(\n",
    "        student_name=student_1[\"name\"],\n",
    "        learning_objectives=student_1[\"learning_objectives\"],\n",
    "        student_profile=student_1[\"profile\"],\n",
    "        context=\"\",\n",
    "        learning_request=\"Generate an individualized learning plan tailored to the student's needs.\",\n",
    "    )\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Student Profile:\n",
      "- Name: David Martinez\n",
      "- Learning Objectives: \n",
      "        Master integer programming techniques.\n",
      "        Explore stochastic models like Markov chains and inventory models.\n",
      "        Build a simulation model for decision-making using Monte Carlo methods.\n",
      "    \n",
      "- Profile Details: \n",
      "        Background: Graduate student pursuing an Industrial Engineering degree with some exposure to optimization.\n",
      "        Strengths: Comfortable with mathematical modeling and programming in Python.\n",
      "        Weaknesses: Lacks practical experience with stochastic and simulation models.\n",
      "        Preferences: Prefers structured lessons with hands-on coding exercises and case studies.\n",
      "    \n",
      "\n",
      "Tasks:\n",
      "1. Based on the provided profile and learning objectives, design a comprehensive learning plan organized into **phases** with specific topics and timeframes. Each phase should build on the previous one, ensuring a structured progression.\n",
      "2. Identify and map content to support each phase and objective. Use additional context if provided. Include recommended resources such as textbooks, online courses, software, or tools that align with the objectives.\n",
      "3. Provide practical study strategies tailored to the student's profile, including time allocations, practice methods, and checkpoint assessments to measure progress.\n",
      "4. Suggest alternative or backup content that can replace primary resources in case of availability issues or better alignment with the student's preferences.\n",
      "5. Respond to the request with text output in the example format.\n",
      "\n",
      "Additional Context:\n",
      "None.\n",
      "\n",
      "Output Format:\n",
      "1. Learning Plan:\n",
      "   - **Phase 1:** [Name] (e.g., Mathematical Foundations) - [Duration]\n",
      "     - [Topics/Objectives and Subtopics]\n",
      "   - **Phase 2:** [Name] (e.g., Core OR Concepts) - [Duration]\n",
      "     - [Topics/Objectives and Subtopics]\n",
      "   - **Phase 3:** [Name] (e.g., Advanced Topics) - [Duration]\n",
      "     - [Topics/Objectives and Subtopics]\n",
      "   - **Phase 4:** [Name] (e.g., Computational Tools) - [Duration]\n",
      "     - [Topics/Objectives and Subtopics]\n",
      "\n",
      "2. Primary Content Mapping:\n",
      "   - Phase 1:\n",
      "     - Subtopic 1: [Resource/Content from NoK]\n",
      "     - Subtopic 2: [Resource/Content from NoK]\n",
      "   - Phase 2:\n",
      "     ...\n",
      "   - Phase 3:\n",
      "     ...\n",
      "   - Phase 4:\n",
      "     ...\n",
      "\n",
      "3. Study Strategies and Tips:\n",
      "   - Weekly schedule template with time allocation for review, practice, problem-solving, and theory.\n",
      "   - Recommended practice methods, such as implementing algorithms, visualization, and community involvement.\n",
      "   - Self-assessment checkpoints.\n",
      "\n",
      "4. Backup Content Suggestions:\n",
      "   - Phase 1:\n",
      "     - Subtopic 1: [Backup Resource]\n",
      "     - Subtopic 2: [Backup Resource]\n",
      "   - Phase 2:\n",
      "     ...\n",
      "   - Phase 3:\n",
      "     ...\n",
      "   - Phase 4:\n",
      "     ...\n",
      "\n",
      "Request: \n",
      "Generate an individualized learning plan tailored to the student's needs.\n",
      "\n",
      "Output:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt2 = prompt_template_2.format(\n",
    "    student_name=student_2[\"name\"],\n",
    "    learning_objectives=student_2[\"learning_objectives\"],\n",
    "    student_profile=student_2[\"profile\"],\n",
    "    context=\"None.\",\n",
    "    learning_request=\"Generate an individualized learning plan tailored to the student's needs.\"\n",
    ")\n",
    "print(prompt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load different KGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GR_kg_no_refine_graph_path = \"../data/generated_graphs/GR_no_refine/final_augmented_graph.graphml\"\n",
    "GR_kg_w_refine_graph_path = \"../data/generated_graphs/GR_w_refine/final_augmented_graph.graphml\"\n",
    "langchain_kg_graph_path = \"../data/generated_graphs/langchain_KG/langchain_full_kg.graphml\"\n",
    "sme_kg_graph_path = \"../data/generated_graphs/SME_graph/DNoKv3.graphml\"\n",
    "\n",
    "#dictionary of graphs\n",
    "graphs_paths = {\n",
    "    \"GR_kg_no_refine\": GR_kg_no_refine_graph_path,\n",
    "    \"GR_kg_w_refine\": GR_kg_w_refine_graph_path,\n",
    "    \"langchain_kg\": langchain_kg_graph_path,\n",
    "    \"sme_kg\": sme_kg_graph_path\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Graph: GR_kg_no_refine\n",
      "-->Number of nodes: 3484, Number of edges: 9841\n",
      "-->example node data: [('C:\\\\Users\\\\jonathan.kasprisin\\\\github\\\\Learning\\\\KG_ilp\\\\data\\\\pdfs\\\\Gilbert_Strang_Linear_Algebra_and_Its_Applicatio_230928_225121.pdf', {'group': 1, 'color': '#57dbc2', 'size': 2497})]\n",
      "-->example edge data: [('C:\\\\Users\\\\jonathan.kasprisin\\\\github\\\\Learning\\\\KG_ilp\\\\data\\\\pdfs\\\\Gilbert_Strang_Linear_Algebra_and_Its_Applicatio_230928_225121.pdf', 'a', {'title': 'is source document of', 'weight': 1.0})]\n",
      "\n",
      "Loaded Graph: GR_kg_w_refine\n",
      "-->Number of nodes: 3049, Number of edges: 9074\n",
      "-->example node data: [('C:\\\\Users\\\\jonathan.kasprisin\\\\github\\\\Learning\\\\KG_ilp\\\\data\\\\pdfs\\\\Gilbert_Strang_Linear_Algebra_and_Its_Applicatio_230928_225121.pdf', {'group': 1, 'color': '#57db8e', 'size': 2363})]\n",
      "-->example edge data: [('C:\\\\Users\\\\jonathan.kasprisin\\\\github\\\\Learning\\\\KG_ilp\\\\data\\\\pdfs\\\\Gilbert_Strang_Linear_Algebra_and_Its_Applicatio_230928_225121.pdf', 'ab', {'title': 'is source document of', 'weight': 1.0})]\n",
      "\n",
      "Failed to load graph langchain_kg from ../data/generated_graphs/langchain_KG/langchain_full_kg.graphml: not well-formed (invalid token): line 3512, column 224\n",
      "Loaded Graph: sme_kg\n",
      "-->Number of nodes: 616, Number of edges: 15649\n",
      "-->example node data: [('0', {'label': \"What's the big idea of Linear Algebra?\", 'title': \"What's the big idea of Linear Algebra?\", 'author': 'trefor bazett', 'content': 'Video', 'year': 2018, 'keywords': 'course intro', 'Clustering Coefficient': 0.6, 'Number of triangles': 6, 'Eigenvector Centrality': 0.036034571942784616, 'Eccentricity': 3.0, 'Closeness Centrality': 0.4399092970521542, 'Harmonic Closeness Centrality': 0.45876288659793746, 'Betweenness Centrality': 0.8319822731595995, 'Weighted Degree': 20.0, 'Modularity Class': 3, 'size': 25.0, 'r': 191, 'g': 122, 'b': 255, 'x': -734.4918, 'y': -91.28125})]\n",
      "-->example edge data: [('0', '1', {'weight': 8.0, 'id': '0'})]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import traceback\n",
    "\n",
    "graph_dict = {}\n",
    "\n",
    "for graph_name, graph_path in graphs_paths.items():\n",
    "\n",
    "    try:\n",
    "        graph= nx.read_graphml(graph_path)\n",
    "        graph_dict[graph_name] = graph\n",
    "\n",
    "        # Print info about the graph\n",
    "        print(f\"Loaded Graph: {graph_name}\")\n",
    "        print(f\"-->Number of nodes: {graph.number_of_nodes()}, Number of edges: {graph.number_of_edges()}\")\n",
    "        print(f\"-->example node data: {list(graph.nodes(data=True))[:1]}\")\n",
    "        print(f\"-->example edge data: {list(graph.edges(data=True))[:1]}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load graph {graph_name} from {graph_path}: {e}\\n\")\n",
    "        #traceback.print_exc()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making nx graph from 983 graph documents\n",
      "nx graph built with 10177 nodes.\n",
      "Example triple: ('Positive Definite Matrices', 'Minima, Maxima, and Saddle Points', 'INCLUDES')\n",
      "Example node: Positive Definite Matrices\n",
      "Example node knowledge: ['Positive Definite Matrices INCLUDES Minima, Maxima, and Saddle Points', 'Positive Definite Matrices INCLUDES Tests for Positive Definiteness', 'Positive Definite Matrices INCLUDES Singular Value Decomposition', 'Singular Value Decomposition DESCRIBED_BY The SVD is closely associated with the eigenvalue-eigenvector factorizationQΛQT of a positive deﬁnite matrix', 'Singular Value Decomposition IS_EXPLAINED_IN Proof of the Singular Value Decomposition', 'Positive Definite Matrices INCLUDES Minimum Principles', 'Positive Definite Matrices INCLUDES The Finite Element Method']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.graphs.networkx_graph import NetworkxEntityGraph\n",
    "import pickle\n",
    "\n",
    "#load langchain graph directly as a NetworkxEntityGraph\n",
    "\n",
    "def make_nxe_graph(graph_documents) -> nx.Graph:\n",
    "    print(f\"Making nx graph from {len(graph_documents)} graph documents\")\n",
    "    graph_nxe = NetworkxEntityGraph()\n",
    "    for doc in graph_documents:\n",
    "        try:\n",
    "            for node in doc.nodes:\n",
    "                graph_nxe.add_node(node.id)\n",
    "            for edge in doc.relationships:\n",
    "                graph_nxe._graph.add_edge(edge.source.id, edge.target.id, relation=edge.type)\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding document to nx graph: {doc.source.metadata}, {e}\")\n",
    "    print(f\"nx graph built with {graph_nxe.get_number_of_nodes()} nodes.\") \n",
    "    return graph_nxe\n",
    "\n",
    "with open(\"../data/generated_graphs/langchain_KG/full_graph_documents.pkl \", \"rb\") as file:\n",
    "    graph_documents = pickle.load(file)\n",
    "\n",
    "save_dir = \"../data/generated_graphs/langchain_KG/\" #save dropped docs\n",
    "\n",
    "filtered_graph_documents = []\n",
    "for doc in graph_documents:\n",
    "    valid_nodes = [node for node in doc.nodes if node.type]\n",
    "    if valid_nodes:\n",
    "        doc.nodes = valid_nodes\n",
    "        filtered_graph_documents.append(doc)\n",
    "    else:\n",
    "        with open(save_dir+\"dropped_docs.txt\", \"a\") as f:\n",
    "            f.write(f\" 'Dropped doc.metadata': '{doc.source.metadata}'\\n\")\n",
    "\n",
    "langchain_nxe_graph = make_nxe_graph(filtered_graph_documents)\n",
    "\n",
    "# Print info about the graph\n",
    "# Try to get node data (adjust method name as needed)\n",
    "try:\n",
    "    triples = langchain_nxe_graph.get_triples()\n",
    "    print(f\"Example triple: {triples[0]}\")\n",
    "    entity= triples[0][0]\n",
    "    print(f\"Example node: {entity}\")\n",
    "    knowledge = langchain_nxe_graph.get_entity_knowledge(entity, 3)\n",
    "    print(f\"Example node knowledge: {knowledge}\")\n",
    "\n",
    "except AttributeError:\n",
    "    print(\"Unable to access node data. Check the class documentation for the correct method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphRAG  custom with community summaries #TODO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/stephenc222/example-graphrag/\n",
    "# 5. Graph Communities → Community Summaries\n",
    "def detect_communities(graph):\n",
    "    communities = []\n",
    "    index = 0\n",
    "    for component in nx.connected_components(graph):\n",
    "        print(\n",
    "            f\"Component index {index} of {len(list(nx.connected_components(graph)))}:\")\n",
    "        subgraph = graph.subgraph(component)\n",
    "        if len(subgraph.nodes) > 1:  # Leiden algorithm requires at least 2 nodes\n",
    "            try:\n",
    "                sub_communities = algorithms.leiden(subgraph)\n",
    "                for community in sub_communities.communities:\n",
    "                    communities.append(list(community))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing community {index}: {e}\")\n",
    "        else:\n",
    "            communities.append(list(subgraph.nodes))\n",
    "        index += 1\n",
    "    print(\"Communities from detect_communities:\", communities)\n",
    "    return communities\n",
    "\n",
    "def summarize_communities(communities, graph):\n",
    "    community_summaries = []\n",
    "    for index, community in enumerate(communities):\n",
    "        print(f\"Summarize Community index {index} of {len(communities)}:\")\n",
    "        subgraph = graph.subgraph(community)\n",
    "        nodes = list(subgraph.nodes)\n",
    "        edges = list(subgraph.edges(data=True))\n",
    "        description = \"Entities: \" + \", \".join(nodes) + \"\\nRelationships: \"\n",
    "        relationships = []\n",
    "        for edge in edges:\n",
    "            relationships.append(\n",
    "                f\"{edge[0]} -> {edge[2]['label']} -> {edge[1]}\")\n",
    "        description += \", \".join(relationships)\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Summarize the following community of entities and relationships.\"},\n",
    "                {\"role\": \"user\", \"content\": description}\n",
    "            ]\n",
    "        )\n",
    "        summary = response.choices[0].message.content.strip()\n",
    "        community_summaries.append(summary)\n",
    "    return community_summaries\n",
    "\n",
    "\n",
    "# 6. Community Summaries → Community Answers → Global Answer\n",
    "def generate_answers_from_communities(community_summaries, query):\n",
    "    intermediate_answers = []\n",
    "    for index, summary in enumerate(community_summaries):\n",
    "        print(f\"Summary index {index} of {len(community_summaries)}:\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Answer the following query based on the provided summary.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Query: {query} Summary: {summary}\"}\n",
    "            ]\n",
    "        )\n",
    "        print(\"Intermediate answer:\", response.choices[0].message.content)\n",
    "        intermediate_answers.append(\n",
    "            response.choices[0].message.content)\n",
    "\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\",\n",
    "                \"content\": \"Combine these answers into a final, concise response.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Intermediate answers: {intermediate_answers}\"}\n",
    "        ]\n",
    "    )\n",
    "    final_answer = final_response.choices[0].message.content\n",
    "    return final_answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
